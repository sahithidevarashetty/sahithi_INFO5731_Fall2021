{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahithidevarashetty/sahithi_INFO5731_Fall2021/blob/main/In_class_exercise_03_10062022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "303TqH_RxUIh"
      },
      "source": [
        "## The third In-class-exercise (10/06/2022, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFU7coIpxUIi"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFn5D3LXxUIj"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Q6Akrv3ZxUIj",
        "outputId": "cd9c5808-d642-4639-dd3a-c1a751f2dd34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\nA text classification task that would be interesting is to predicent the sentiment of a sentence or paragraph. In order to\\ndo this, a list of features that might be helpful are the following\\n\\n1. count vectors - gives the count of words in a sentence or given texyt\\n2. TF-IDF vectors - these vectors represent importance of words relative to each other in a given sample\\n3. Frequency distribution of POS - parts of speech - like nouns, verbs, and adjectives\\n4. word-density vectors - gives the average length of words in corpus\\n5. N-gram TF-DIF vectors - represents tf-idf scores of n words \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "A text classification task that would be interesting is to predicent the sentiment of a sentence or paragraph. In order to\n",
        "do this, a list of features that might be helpful are the following\n",
        "\n",
        "1. count vectors - gives the count of words in a sentence or given texyt\n",
        "2. TF-IDF vectors - these vectors represent importance of words relative to each other in a given sample\n",
        "3. Frequency distribution of POS - parts of speech - like nouns, verbs, and adjectives\n",
        "4. word-density vectors - gives the average length of words in corpus\n",
        "5. N-gram TF-DIF vectors - represents tf-idf scores of n words \n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3O5iXQxxUIk"
      },
      "source": [
        "Question 2 (20 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuJUiSNtxUIl",
        "outputId": "9b61e1dd-385d-4f60-8fb0-e57f2b44f193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Matrix: \n",
            "  (0, 8)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 1)\t1\n",
            "  (1, 8)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 1)\t2\n",
            "  (1, 5)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 3)\t1\n",
            "  (2, 6)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 4)\t1\n",
            "  (3, 8)\t1\n",
            "  (3, 3)\t1\n",
            "  (3, 6)\t1\n",
            "  (3, 2)\t1\n",
            "  (3, 1)\t1\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "corpus = [\n",
        "     'This is the first document.',\n",
        "     'This document is the second document.',\n",
        "     'And this is the third one.',\n",
        "     'Is this the first document?',\n",
        "]\n",
        "\n",
        "#1. \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(\"Count Matrix: \")\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. TF-IDF Vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names())\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlneCOqx9NfX",
        "outputId": "ee30e938-97a0-4414-84f1-f99898eec357"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "  (0, 1)\t0.46979138557992045\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 8)\t0.38408524091481483\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.46979138557992045\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 8)\t0.38408524091481483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Frequency distribution of POS\n",
        "#import nltk library\n",
        "import nltk\n",
        "from collections import Counter\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def pos_freq(sentence):\n",
        "  words = nltk.word_tokenize(sentence.lower())\n",
        "  p = nltk.pos_tag(words)\n",
        "  freq = Counter(t for _, t in p)\n",
        "  return freq\n",
        "\n",
        "for sentence in corpus:\n",
        "  print(pos_freq(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j7cu6PF9zOn",
        "outputId": "73952645-e601-4807-ebeb-ae6a505eadfa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'DT': 2, 'VBZ': 1, 'JJ': 1, 'NN': 1, '.': 1})\n",
            "Counter({'DT': 2, 'NN': 2, 'VBZ': 1, 'JJ': 1, '.': 1})\n",
            "Counter({'DT': 2, 'CC': 1, 'VBZ': 1, 'JJ': 1, 'CD': 1, '.': 1})\n",
            "Counter({'DT': 2, 'VBZ': 1, 'JJ': 1, 'NN': 1, '.': 1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. \n",
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "df['text'] = corpus\n",
        "\n",
        "df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
        "df['density'] = df['text'].apply(len) / (df['word_count']+1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "ZYN7iRLo-pHL",
        "outputId": "51aa9bc3-6130-4130-b9ab-7986ca279db4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    text  word_count   density\n",
              "0            This is the first document.           5  4.500000\n",
              "1  This document is the second document.           6  5.285714\n",
              "2             And this is the third one.           6  3.714286\n",
              "3            Is this the first document?           5  4.500000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e3d530d-b214-4c92-a7f5-aea8c7a9a1ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>word_count</th>\n",
              "      <th>density</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is the first document.</td>\n",
              "      <td>5</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This document is the second document.</td>\n",
              "      <td>6</td>\n",
              "      <td>5.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>And this is the third one.</td>\n",
              "      <td>6</td>\n",
              "      <td>3.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is this the first document?</td>\n",
              "      <td>5</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e3d530d-b214-4c92-a7f5-aea8c7a9a1ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e3d530d-b214-4c92-a7f5-aea8c7a9a1ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e3d530d-b214-4c92-a7f5-aea8c7a9a1ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. N-gram TF-IDF vectors\n",
        "n_gram_vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "X = n_gram_vectorizer.fit_transform(corpus)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVEE6Rb__Hfi",
        "outputId": "c345cbd9-5fd4-4d4b-b1fc-69a29ba3bfc1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 13)\t0.37102749370236965\n",
            "  (0, 6)\t0.4706013296756691\n",
            "  (0, 22)\t0.37102749370236965\n",
            "  (0, 4)\t0.37102749370236965\n",
            "  (0, 12)\t0.37102749370236965\n",
            "  (0, 5)\t0.300378732756136\n",
            "  (0, 21)\t0.37102749370236965\n",
            "  (1, 15)\t0.34488068892940316\n",
            "  (1, 7)\t0.34488068892940316\n",
            "  (1, 3)\t0.34488068892940316\n",
            "  (1, 20)\t0.34488068892940316\n",
            "  (1, 11)\t0.34488068892940316\n",
            "  (1, 14)\t0.34488068892940316\n",
            "  (1, 2)\t0.34488068892940316\n",
            "  (1, 19)\t0.34488068892940316\n",
            "  (1, 5)\t0.2201328763012063\n",
            "  (2, 17)\t0.361536687086221\n",
            "  (2, 8)\t0.361536687086221\n",
            "  (2, 1)\t0.361536687086221\n",
            "  (2, 18)\t0.361536687086221\n",
            "  (2, 16)\t0.361536687086221\n",
            "  (2, 0)\t0.361536687086221\n",
            "  (2, 22)\t0.28503967675464414\n",
            "  (2, 5)\t0.23076418416976147\n",
            "  (2, 21)\t0.28503967675464414\n",
            "  (3, 24)\t0.4129278840793483\n",
            "  (3, 10)\t0.4129278840793483\n",
            "  (3, 23)\t0.4129278840793483\n",
            "  (3, 9)\t0.4129278840793483\n",
            "  (3, 13)\t0.3255570867497791\n",
            "  (3, 4)\t0.3255570867497791\n",
            "  (3, 12)\t0.3255570867497791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A7HCNp2xUIl"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "WYsQlHVUxUIl",
        "outputId": "af5de76e-38c6-4d4a-c5e5-c991fa16a8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6515151515151515\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIt looks like count vector has a pretty high score of predicting the sentiment of a text. There it is the most important feature among all the selected features\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "# The above code only shows examples of features in sample data\n",
        "\n",
        "# More data is used to perform feature selection \n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame()\n",
        "data = open('data.csv').read()\n",
        "labels = list()\n",
        "texts = list()\n",
        "for line in data.split(\"\\n\"):\n",
        "    labels.append(line.split()[0])\n",
        "    texts.append(\" \".join(line.split()[1:]))\n",
        "\n",
        "df['text'] = texts\n",
        "df['label'] = labels\n",
        "df.head()\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['text'], df['label'])\n",
        "\n",
        "e = preprocessing.LabelEncoder()\n",
        "train_y = e.fit_transform(train_y)\n",
        "valid_y = e.fit_transform(valid_y)\n",
        "\n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(df['text'])\n",
        "\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)\n",
        "\n",
        "from sklearn import metrics\n",
        "def train_model(model, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    model.fit(feature_vector_train, label)\n",
        "    predictions = model.predict(feature_vector_valid)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, valid_y)\n",
        "\n",
        "from sklearn import naive_bayes\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "\"\"\"\n",
        "It looks like count vector has a pretty high score of predicting the sentiment of a text. There it is the most important feature among all the selected features\n",
        "\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}